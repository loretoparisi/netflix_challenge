#!/usr/bin/env python2

# This script carries out quiz bin blending on the predictions stored in
# the data/quiz_blend directory (which were presumably generated by
# predictors trained on all of quiz). For more details, refer to:
#
#   http://www.its.caltech.edu/~dlinghu/quiz-bin-blending.pdf
#
# This script should be executed at the top level of this repo. It takes
# the output file's name as a required argument, and also takes a "-v" or
# "--verbose" optional argument.
#
# NOTE: A bins.dta file must be present in data/quiz_bin_blend. This
# specifies the bin that each element in qual belongs to. The number of
# elements in this must equal the number of elements in qual. You can
# generate this file by running generate_bins.py. Remember to change
# NUM_BINS below too.
#

from mechanize import ParseResponse, urlopen, HTTPError, urljoin
import numpy as np
import matplotlib.pyplot as plt
import glob
import shutil
import os
import math
import sys


# Constants

# The blending directory (relative to this repo's topmost directory).
QBLEND_DIR = "data/quiz_blend/"

# The extension of predictor data.
PRED_EXT = ".dta"

# Regularization constant for our linear regression. This value came from
# BigChaos's 2009 paper.
#
# Note: value changed to 0.0 since we have fairly small bins (so large
# LAMBDAs really worsen the regression). This might have led to overfitting
# on the quiz set...
LAMBDA = 0.0 # 0.0014

# The number of ratings in the qual set. This is used to standardize X
# before regressing. Note that this is referred to as N_L below.
NUM_QUAL_RAT = 2749898

# The sum of the squared ratings in the quiz set, i.e. 1/N_Q sum_u y_u^2
# This is found by making a 0-only submission.
QSSR = 3.84358**2.0

# The minimum and maximum ratings that we'll allow in the outputs. These
# were chosen by just trying various combinations and submitting them to
# the scoreboard.
MIN_BLEND_RATING = 1.0
MAX_BLEND_RATING = 5.0

# The location where bins are kept for each of the qual entries.
BIN_FILE = "data/quiz_bin_blend/bins.dta"

# The number of bins must be between 0 (inclusive) and NUM_BINS
# (exclusive).
NUM_BINS = 15

# The location where the cache will be stored for various predictors'
# mappings for various bins. The entries in this cache will be of the form
# <PREDICTOR FILE NAME> <BIN> <LAST_TWO_TERMS>, where "LAST_TWO_TERMS" is a
# reference to Kevin Linghu's previously-mentioned PDF.
CACHE = "data/quiz_bin_blend/last_two_terms_cache.dta"

# A temporary cache file, to use when writing new entries.
TEMP_CACHE = "data/quiz_bin_blend/temp_last_two_terms_cache.dta"

# This is the file where we'll store the previous run's cached data, just
# in case it's useful.
OLD_CACHE = "data/quiz_bin_blend/old_last_two_terms_cache.dta"

# If True, we'll try to use the cache file to see if there's any entries
# we've precomputed. If false, everything will be recomputed.
READING_FROM_CACHE = True

# We're always writing to the cache in TEMP_CACHE, no matter what.

# The scoreboard submission website
SCOREBOARD_SUB_URL = "http://cs156.caltech.edu/scoreboard/"

# Our team ID
TEAM_ID = "rwmywvgo"

# Strings to search for in the submission page.
QRMSE_STR_BEGIN = "Your current submission RMSE: "
QRMSE_STR_END = "water)"

# A temporary file we'll use to write predictions to as we submit them to
# the scoreboard.
TEMP_PRED_FN = "data/quiz_bin_blend/temp_pred.dta"


# Prints a usage statement for this program, and then exits.
def usage(progName):
    # This program either takes one or two argument(s). If it is given two
    # argument, one argument must be a verbose flag.
    print "usage: python2 " + progName + " [-v] outputFile\n\n" +\
          "optional arguments:\n" +\
          "  -v, --verbose\tprint additional status outputs";
    sys.exit(1)


# The main quiz bin-blending function. See
# http://www.its.caltech.edu/~dlinghu/quiz-bin-blending.pdf and the
# quiz_blend.py script for more details.
#
def main():

    # This script only takes exactly one or two arguments.
    if len(sys.argv) != 2 and len(sys.argv) != 3:
        usage(sys.argv[0])

    # Verbose flag
    verbose = False
    verboseFlagFound = False

    # The output file's name
    outputFileName = None

    # If there's one arg, then it's the output file's name. If there's two
    # args, one should be the verbose flag.
    for i in range(1, len(sys.argv)):
        if sys.argv[i] == "-v" or sys.argv[i] == "--verbose":
            verbose = True
            verboseFlagFound = True
        else:
            outputFileName = sys.argv[i]

    if outputFileName == None or \
        (len(sys.argv) == 3 and not verboseFlagFound):
        # No output file found.
        usage(sys.argv[0])

    # Load the BIN_FILE and store it in memory.

    if verbose:
        print "Reading in segregation data for", NUM_BINS, "bins in file",\
              BIN_FILE

    binFileMem = np.loadtxt(BIN_FILE)

    # Use this to populate a mapping from (binNum, indInBin) to index in
    # qual. This also requires keeping track of each bin's counts.
    binNumBinIndToQualInd = dict()
    binIndexCounts = np.zeros(NUM_BINS)

    qualInd = 0

    for entry in binFileMem:
        thisBinCount = binIndexCounts[entry]

        # Map this (binNum, indInBin) tuple to qualInd
        binNumBinIndToQualInd[(entry, thisBinCount)] = qualInd

        binIndexCounts[entry] += 1
        qualInd += 1

    # Check that we have the correct number of qual ratings.
    assert qualInd == NUM_QUAL_RAT

    if verbose:
        print "Finished reading in segregation data."
        print "Bin distribution:", binIndexCounts

    # Read in the number of predictors and instantiate their names.
    numPredictors = 0

    if verbose:
        print "Using predictors in", QBLEND_DIR

    # Find how many prediction files there are in the quiz blend directory,
    # and store their names (in alphabetical order).
    predFiles = glob.glob(QBLEND_DIR + "*" + PRED_EXT)
    predFiles = sorted(predFiles)

    predNames = list()

    for predFile in predFiles:
        # Ignore the part before the QBLEND_DIR (including the "/"), but
        # keep the QRMSE and extension.
        afterDirStart = predFile.rindex(QBLEND_DIR) + len(QBLEND_DIR)
        predName = predFile[afterDirStart:]

        predNames.append(predName)
        numPredictors += 1

    if verbose:
        print "Found", numPredictors, "predictor(s) in", QBLEND_DIR

    # Predictor parsing and segregation

    # A dict that maps from a bin number to the 2D array X associated with
    # that bin. The array X will be binIndexCounts[binNum] x numPredictors
    # in shape.
    binNumToX = dict()

    for binNum in range(NUM_BINS):
        # Instantiate an array X of shape binIndexCounts[binNum] x
        # numPredictors.
        thisBinX = np.zeros((binIndexCounts[binNum], numPredictors))
        binNumToX[binNum] = thisBinX

    # Parse all of the prediction files in order to load up X and predQRMSEs
    if verbose:
        print "\nReading in and segregating predictor files..."

    for predInd in range(numPredictors):
        fileName = predFiles[predInd]

        # Get the predictor's name, as stored earlier.
        predName = predNames[predInd];

        # Parse the data in this prediction file. Make sure the number of
        # lines equals NUM_QUAL_RAT as expected.
        lineNum = 0

        # Keep track of the number of entries encountered in each bin for
        # each predictor.
        thisPredBinIndexCounts = np.zeros(NUM_BINS)

        # Store the entries and segregate them into bins.
        with open(fileName, "r") as predFile:

            for line in predFile:
                thisPredBin = binFileMem[lineNum]

                # Look up the appropriate X matrix.
                thisX = binNumToX[thisPredBin]

                # Write to the appropriate entry in the X matrix. This
                # entry will be standardized *later*.
                thisPredXRow = thisPredBinIndexCounts[thisPredBin];

                thisX[thisPredXRow, predInd] = float(line)

                thisPredBinIndexCounts[thisPredBin] += 1
                lineNum += 1

        assert lineNum == NUM_QUAL_RAT

        if verbose:
            print "Finished segregating data for predictor " + predName +\
                  "."

    # Standardize all Xs by dividing them by sqrt(NUM_QUAL_RAT).
    for binNum in range(NUM_BINS):
        thisX = binNumToX[binNum]
        thisX /= math.sqrt(NUM_QUAL_RAT)

    if verbose:
        print "Finished reading in predictor files."

    # The output blended predictions (populated later)
    blendedPred = np.zeros(NUM_QUAL_RAT)

    # Preload data from the cache, to avoid resubmitting to the Internet.
    # We'll use a mapping from (predictorName, binNum) to "lastTwoTerms",
    # where the "predictorName" is the name stored in predNames and
    # "lastTwoTerms" is the sum of the last two terms in David Linghu's
    # PDF.
    predNameBinNumToLastTwoTerms = dict()

    # Check if we're reading in from the cache, and if the CACHE file even
    # exists.
    if READING_FROM_CACHE and os.path.isfile(CACHE):
        cacheIn = open(CACHE, "r")

        for line in cacheIn:
            thisLineSplit = line.split()
            thisPredName = thisLineSplit[0]
            thisBin = int(thisLineSplit[1])
            thisLastTwoTerms = float(thisLineSplit[2])

            predNameBinNumToLastTwoTerms[(thisPredName, thisBin)] = \
                    thisLastTwoTerms

        cacheIn.close()

    # Keep a cache of the sum of the "last two terms"
    tempCache = open(TEMP_CACHE, "w")


    # Compute the predictions for each individual bin by finding the beta
    # for that bin. Then populate the relevant entries in blendedPred after
    # this is all done.
    for binNum in range(NUM_BINS):
        # This is X for this bin.
        X = binNumToX[binNum]

        # The number of ratings in this bin. Used to un-standardize.
        numBinRatings = binIndexCounts[binNum]

        # Compute (X^T * X + LAMBDA * I). Note that X is standardized
        # already.
        xTransXPlusLam = (X.T).dot(X) +\
                LAMBDA * np.identity(numPredictors)

        # We'll estimate X^T * y for this bin, and store it here.
        xTransYEst = np.zeros((numPredictors, 1))

        print "\n"

        for predInd in range(numPredictors):
            # This column in X.
            thisCol = X[:, predInd]

            # This predictor's name (including the QRMSE and extension).
            thisPredName = predNames[predInd]

            # Get the sum of the squared elements in this column.
            sumSquareElem = np.sum(np.square(thisCol))

            # We now need to get the (sum of the) "last two terms" in David
            # Linghu's PDF. We can either get these by checking the cache
            # or regenerating (if there's a cache miss).
            lastTwoTerms = 0.0

            if (thisPredName, binNum) in predNameBinNumToLastTwoTerms:
                lastTwoTerms = predNameBinNumToLastTwoTerms\
                        [(thisPredName, binNum)]
            else:
                # We need to regenerate the prediction from the scoreboard
                # submission page. First, recreate the prediction by making
                # a submission with all zeros *except* for the predictions
                # made by this predictor in this bin. We'll save this to
                # TEMP_PRED_FN.
                tempPredArr = np.zeros((NUM_QUAL_RAT, 1))

                for indInBin in range(len(thisCol)):
                    # Look up the index in "qual" corresponding to this bin
                    # and indInBin.
                    qualInd = binNumBinIndToQualInd[(binNum, indInBin)]

                    # Write to the appropriate entry of tempPredArr.
                    tempPredArr[qualInd, 0] = thisCol[indInBin] *\
                            math.sqrt(NUM_QUAL_RAT)

                # Save the temporary prediction to TEMP_PRED_FN, before we
                # can upload it.
                np.savetxt(TEMP_PRED_FN, tempPredArr, '%0.3f')

                # Upload the file at TEMP_PRED_FN to the scoreboard. Start
                # by navigating to the submission form.
                response = urlopen(SCOREBOARD_SUB_URL)
                forms = ParseResponse(response, backwards_compat=False)
                form = forms[0]

                # Use User-Movie order.
                form["valset"] = ["1"];

                # Use our team ID
                form["teamid"] = TEAM_ID;

                # Upload the file at TEMP_PRED_FN.
                form.add_file(open(TEMP_PRED_FN), "text/plain",
                              TEMP_PRED_FN, name="file")

                # Submit the form and wait for a response.
                request2 = form.click()
                response2 = None

                try:
                    response2 = urlopen(request2)
                except HTTPError, response2:
                    print "Failed to get a response from the server. " +\
                          "Aborting..."
                    sys.exit(1)

                # Otherwise, read the response, and look for the QRMSE.
                corpus = response2.read()

                initialStartInd = corpus.rindex(QRMSE_STR_BEGIN) + \
                        len(QRMSE_STR_BEGIN)
                initialEndInd = corpus.rindex(QRMSE_STR_END)

                narrowerCorpus = corpus[initialStartInd:initialEndInd]

                # Read up to the parenthesis in narrowerCorpus.
                newEndInd = narrowerCorpus.rindex(" (")
                submissionQRMSE = float(narrowerCorpus[:newEndInd])

                print "Submission QRMSE:", submissionQRMSE

                # The "last two terms" are just the submission QRMSE
                # squared.
                lastTwoTerms = submissionQRMSE**2.0

            # Write the "last two terms" to the tempCache for now.
            tempCache.write(thisPredName + " " + str(binNum) + " " +
                            str(lastTwoTerms) + "\n")

            # The relevant term in X^T * y for this bin is 0.5 *
            # (sumSquareElem + QSSR - lastTwoTerms)
            xTransYEst[predInd, 0] = 0.5 * (sumSquareElem + QSSR -
                    lastTwoTerms)

            if verbose:
                print "Computed X^T * y for bin", binNum, "predictor",\
                      thisPredName

        # Compute beta = (X^T * X + LAMBDA * I)^(-1) * (X^T * y) for this
        # bin.
        betaBin = (np.linalg.inv(xTransXPlusLam)).dot(xTransYEst)

        if verbose:
            print "\nBin " + str(binNum) + ":"
            print "Sum of elements in un-normalized beta:", np.sum(betaBin)

            # betaBin /= np.sum(betaBin)
            print "Elements in un-normalized beta:"

            for i in range(len(betaBin)):
                print "    * " + predNames[i] + ": " +\
                        str('%0.3f' % betaBin[i, 0])

        # The predictions for this bin are then given by X * betaBin. We
        # will write these out to the appropriate qual entries in
        # blendedPred.
        binPred = X.dot(betaBin) * math.sqrt(NUM_QUAL_RAT)

        for indInBin in range(len(binPred)):
            qualInd = binNumBinIndToQualInd[(binNum, indInBin)]

            # TODO: possibly remove precondition check.
            # assert blendedPred[qualInd] == 0.0
            blendedPred[qualInd] = binPred[indInBin, 0]

    tempCache.close()

    # Move the old cache from CACHE into OLD_CACHE
    if os.path.isfile(CACHE):
        shutil.move(CACHE, OLD_CACHE)

    # Move the newly-cached results from TEMP_CACHE into CACHE.
    shutil.move(TEMP_CACHE, CACHE)

    # Remove the temporary prediction file.
    if os.path.isfile(TEMP_PRED_FN):
        os.remove(TEMP_PRED_FN)

    if verbose:
        print "\nUpdated \"last two term\" cache in " + CACHE + "."

    # The final list of blended predictions is in blendedPred. Clip the
    # values in this array and then save it to file.
    blendedPred = np.clip(blendedPred, MIN_BLEND_RATING, MAX_BLEND_RATING)

    if verbose:
        print "\nClipped blended predictions to range [" +\
              str(MIN_BLEND_RATING) + ", " + str(MAX_BLEND_RATING) + "]"

    # Save to the specified output file.
    np.savetxt(outputFileName, blendedPred, '%0.3f')

    print "Saved blended predictions to", outputFileName


if __name__ == "__main__":
    main()
