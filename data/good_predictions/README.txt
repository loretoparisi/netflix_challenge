This folder contains the "good" qual and "probe" predictions we got for
single-algorithm and multi-algorithm approaches. The files' names specify
the kind of algorithm, the dataset that we trained on, and our percentage
above water. For instance, SVDPP_PROBE_4.5.dta would mean that file
contains ratings generated by SVD++ on the "probe" dataset that brought us
4.5% above water.  Combined/blended algorithms can be denoted with extra
underscores, or they can have names like BLEND1_QUAL_6.0.dta. The
correspondence between blend names and their contents should be included
below.



Further details on predictions in this folder:

TIMESVDPP_QUAL_7.765: This was generated on May 7 at 10:00 am. The internal
parameters were unchanged relative to TIMESVDPP_QUAL_7.749, but I instead
carried out *40 iterations* of training with 110 factors and 30 time
bins. More than 40 iterations seems to lead to some amount of overfitting
(although it's very slight).


TIMESVDPP_QUAL_7.749: This was generated on May 7 at 12:14 am. TimeSVD++
with frequency-dependent terms and item-dependent bin terms was carried out
for 25 iterations with 110 factors and 30 time bins (for item biases and
item factors). Training was carried out on all of the training data, and
testing was done on the "qual" set (the reported RMSE is a quiz RMSE). To
initialize the internal data of the TimeSVDPP, we used the following
approach:
    * Initialize userFacMat to random values in [-0.005, 0.005]
    * Initialize itemFacMat with a similar range of random values.
    * Initialize itemFacMatTimewise with a similar range of random values.
    * Initialize yMat with a similar range of random values.
    * Initialize cUserConst with 1s.
    * Initialize bUserConst, bUserAlpha, userFacMatAlpha, bItemConst,
      bItemTimewise, bItemFreq, and itemFacMatFreq to all zeros.
    * Initialize the sparse bUserTime and cUserTime matrices with small
      values of 1.0e-9.
    * Initialize userFacMatTime's vectors to all zeros.

As for our regularization constants and learning rates, we chose:
    * Regularization:
        * TIMESVDPP_LAM_B_U = 0.0065
        * TIMESVDPP_LAM_ALPHA_B_U = 0.0004
        * TIMESVDPP_LAM_B_U_T = 0.0050
        * TIMESVDPP_LAM_B_I = 0.005
        * TIMESVDPP_LAM_B_I_T = 0.0050
        * TIMESVDPP_LAM_B_I_F_U_T = 4.40e-3
        * TIMESVDPP_LAM_C_U = 0.010
        * TIMESVDPP_LAM_C_U_T = 0.0070
        * TIMESVDPP_LAM_Q_I = 0.0155
        * TIMESVDPP_LAM_Q_I_BIN = 0.022
        * TIMESVDPP_LAM_Q_I_F = 0.018
        * TIMESVDPP_LAM_P_U = 0.0155
        * TIMESVDPP_LAM_ALPHA_P_U = 0.0004
        * TIMESVDPP_LAM_P_U_T = 0.015
        * TIMESVDPP_LAM_Y_J = 0.0155
    * Learning rates:
        * TIMESVDPP_GAMMA_B_U = 0.0054
        * TIMESVDPP_GAMMA_ALPHA_B_U = 0.00003
        * TIMESVDPP_GAMMA_B_U_T = 0.0028
        * TIMESVDPP_GAMMA_B_I = 0.005
        * TIMESVDPP_GAMMA_B_I_T = 0.0001
        * TIMESVDPP_GAMMA_B_I_F_U_T = 0.00236
        * TIMESVDPP_GAMMA_C_U = 0.006
        * TIMESVDPP_GAMMA_C_U_T = 0.001
        * TIMESVDPP_GAMMA_Q_I = 0.005
        * TIMESVDPP_GAMMA_Q_I_BIN = 0.0007
        * TIMESVDPP_GAMMA_Q_I_F = 0.00003
        * TIMESVDPP_GAMMA_P_U = 0.0050
        * TIMESVDPP_GAMMA_ALPHA_P_U = 0.00001
        * TIMESVDPP_GAMMA_P_U_T = 0.0040
        * TIMESVDPP_GAMMA_Y_J = 0.0050
    * Learning rate decay (common to all rates):
        * TIMESVDPP_GAMMA_MULT_PER_ITER = 0.89


SVDPP_QUAL_6.239: This was generated on April 30 at 6:28 pm. SVD++ was run
for 25 iterations with 200 factors. Fewer iterations were chosen since 30
iterations were found to cause overfitting. Training was carried out on the
"base", "hidden", and "valid" sets, and testing was done on the "qual" set.

The regularization parameters, learning rates, and learning rate decays
were unchanged from before. All that was changed was initialization, as
follows:
    * bUser, bItem, and yMat were initialized to all zeros.
    * userFacMat and itemFacMat were initialized according to
      http://www.netflixprize.com/community/viewtopic.php?id=1342&p=3.


TIMESVDPP_QUAL_6.963: This was generated on April 30 at 3:48 pm. Unlike
previous versions, we used SVD++^(3) for this. We ran 130 factors for 30
iterations and with 30 time bins. Training was done on "base", "hidden",
and "valid", and testing was done on the "qual" set (the reported RMSE is
the "quiz" RMSE). To initialize the internal data of the TimeSVDPP, we used
the following approach:
    * Initialize bUserConst, bUserAlpha, userFacMatAlpha, bItemConst,
      bItemTimewise, and yMat to all zeros.
    * Initialize userFacMat and itemFacMat according to the suggestions in
      http://www.netflixprize.com/community/viewtopic.php?id=1342&p=3.
    * Batch-initialize bUserTime as before.
    * Fill the corresponding entries in userFacMatTime at the very
      beginning of train(). The vectors are filled with zeros.

As for our regularization parameters and learning rates, we used:
    * Regularization:
        * Same as before, with the addition of:
        * TIMESVDPP_LAM_P_U_T = 0.015;
    * Learning rates:
        * Same as before, with the addition of:
        * TIMESVDPP_GAMMA_P_U_T = 0.003
    * Learning rate decay (common to all rates): Same as before


TIMESVDPP_QUAL_6.904: This was generated on April 26 at 7:49 am. The
parameters are the same as the ones in TIMESVDPP_QUAL_6.829, except the
number of factors was increased to 500. Surprisingly, overfitting was
avoided (even though there are ~800 million parameters at this point, of
which ~770 million are user/movie features). Both the probe error and the
quiz error went down (by approximately the same RMSE of ~0.0007) relative
to the 200-factor case. This might be the best performance we can get out
of TimeSVD++, without adding even more sophistication (which would take up
too much memory).


TIMESVDPP_QUAL_6.829: This was generated on April 25 at 5:05 pm. TimeSVD++
was carried out for 30 iterations with 200 factors and 30 time bins (for
item biases). Training was carried out on the "base", "hidden", and "valid"
sets, and testing was done on the "qual" set (the reported RMSE is actually
the "quiz" RMSE of course). To initialize the internal data of the
TimeSVDPP, we used the following approach:
    * Initialize bUserConst, bUserAlpha, userFacMatAlpha, bItemConst,
      bItemTimewise, and yMat to all zeros. It makes sense for most of
      these to be zero since they're essentially item biases, user biases,
      and time biases.
    * The matrix bUserTime is a sparse matrix, but we batch-initialize its
      nonzero entries to 0.0000001 at the beginning of our training method
      (this cuts down on the first iteration's time; otherwise, we'd have
      to update the sparse matrix one by one).
    * The matrices userFacMat and itemFacMat have all of their entries
      initialized to std::rand() % 14000 + 2000) * 0.000001235 *
      std::copysign(1.0, coinFlip(engine), where the "copysign" part
      essentially just produces a random sign based on a "coin flip". This
      method was suggested in a Netflix forum post (see code).

As for our regularization constants and learning rates, we chose:
    * Regularization:
        * TIMESVDPP_LAM_B_U = 0.005
        * TIMESVDPP_LAM_ALPHA_B_U = 0.0004
        * TIMESVDPP_LAM_B_U_T = 0.005 
        * TIMESVDPP_LAM_B_I = 0.005
        * TIMESVDPP_LAM_B_I_T = 0.005
        * TIMESVDPP_LAM_Q_I = 0.015
        * TIMESVDPP_LAM_P_U = 0.015
        * TIMESVDPP_LAM_ALPHA_P_U = 0.0004
        * TIMESVDPP_LAM_Y_J = 0.015
    * Learning rates:
        * TIMESVDPP_GAMMA_B_U = 0.007;
        * TIMESVDPP_GAMMA_ALPHA_B_U = 0.00001;
        * TIMESVDPP_GAMMA_B_U_T = 0.007;
        * TIMESVDPP_GAMMA_B_I = 0.007;
        * TIMESVDPP_GAMMA_B_I_T = 0.007;
        * TIMESVDPP_GAMMA_Q_I = 0.007;
        * TIMESVDPP_GAMMA_P_U = 0.007;
        * TIMESVDPP_GAMMA_ALPHA_P_U = 0.00001;
        * TIMESVDPP_GAMMA_Y_J = 0.007;
    * Learning rate decay (common to all rates):
        * TIMESVDPP_GAMMA_MULT_PER_ITER = 0.9


SVDPP_QUAL_6.193: This was generated on April 17 at 3:17 am. SVD++ was run
for 30 iterations with 200 factors. Training was carried out on the "base",
"hidden", and "valid" sets, and testing was done on the "qual" set. The
following constants were used:
    * Regularization:
        * SVDPP_LAM_B_I = 0.005
        * SVDPP_LAM_B_U = 0.030
        * SVDPP_LAM_Q_I = 0.006
        * SVDPP_LAM_P_U = 0.080
        * SVDPP_LAM_Y_J = 0.030
    * Learning rates:
        * SVDPP_GAMMA_B_I = 0.003
        * SVDPP_GAMMA_B_U = 0.012
        * SVDPP_GAMMA_Q_I = 0.011
        * SVDPP_GAMMA_P_U = 0.006
        * SVDPP_GAMMA_Y_J = 0.001
    * Learning rate decay (common to all rates):
        * SVDPP_GAMMA_MULT_PER_ITER = 0.9


SVD with 200 features and 60 iterations: 0.91416 (3.91% above water)
    * alpha1, alpha2 are 0.008
    * beta1, beta2 are 0.01

