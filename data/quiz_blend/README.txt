NOTE FROM LAKSH:
None of these predictions were generated by algorithms running on the
entire training set. So, feel free to get rid of the files in here later on
and replace them with more appropriate ones for quiz-blending purposes.


===========================================================================
INTRODUCTION
===========================================================================

This it the directory where predictions on "qual" will be stored, before
they are blended via quiz blending (see src/quiz_blend.py). It is assumed
that each of the training algorithms used were trained on all of the data,
i.e. base, hidden, valid, and probe.

Each of the files in this folder must follow this convention: their names
must end with "_QRMSE_<QUIZ RMSE>.dta", where <QUIZ RMSE> is the RMSE that
that specific predictor achieved on the quiz dataset. Typically, the name
will start off with a description of the algorithm and the general
parameters (e.g. epochs, number of factors) used. An example name is:
    
    TIMESVDPP_FAC_130_EPOCH_30_QRMSE_0.88515.dta

If additional details are required, they will be added below.


===========================================================================
ADDITIONAL DETAILS
===========================================================================


TIME-SVD++ (overfit)
---------------------

TIMESVDPP_NO_UFMT_FAC_50_EPOCH_80_QRMSE_0.8839: See TIMESVDPP_QUAL_7.095 in
"good_predictions".

TIMESVDPP_NO_UFMT_FAC_1000_EPOCH_80_QRMSE_0.87726: See TIMESVDPP_QUAL_7.793
in "good_predictions".

TIMESVDPP_FAC_30_EPOCH_80_QRMSE_0.89825: See TIMESVDPP_QUAL_5.587 in
"good_predictions".

TIMESVDPP_FAC_60_EPOCH_80_QRMSE_0.88616: See TIMESVDPP_QUAL_6.857 in
"good_predictions".

TIMESVDPP_FAC_200_EPOCH_80_QRMSE_0.88436: See TIMESVDPP_QUAL_7.046 in
"good_predictions".

TIMESVDPP_FAC_300_EPOCH_80_QRMSE_0.88275: See TIMESVDPP_QUAL_7.216 in
"good_predictions". This run did use userFacMatTime, and was overfitted
with an LRD of 0.945.

TIMESVDPP_FAC_110_EPOCH_80_QRMSE_0.87817: See TIMESVDPP_QUAL_7.697 in
"good_predictions". This run did use userFacMatTime, and was slightly
overfitted (learning rate decay set to 0.90).

TIMESVDPP_FAC_60_EPOCH_80_QRMSE_0.87924: See TIMESVDPP_QUAL_7.585 in
"good_predictions". This run used userFacMatTime and was overfitted
(learning rate decay set to 0.915).


TIME-SVD++ (not overfit)
-------------------------

TIMESVDPP_FAC_80_EPOCH_25_QRMSE_0.88638: See TIMESVDPP_QUAL_6.834 in
"good_predictions".

TIMESVDPP_FAC_130_EPOCH_30_QRMSE_0.88515: this is SVD++^(3), generated
using the parameters specified in "good_predictions" for
TIMESVDPP_QUAL_6.963.dta. Note that this has not been trained on probe.

TIMESVDPP_FAC_500_EPOCH_30_QRMSE_0.88572: this is SVD++^(1), generated
using the parameters specified in "good_predictions" for
TIMESVDPP_QUAL_6.904.dta. Note that this has **not** been trained on
probe.

TIMESVDPP_FAC_345_EPOCH_40_QRMSE_0.87629: See TIMESVDPP_QUAL_7.895 in
"good_predictions". This run did use userFacMatTime, and took up almost the
full 32 GB of RAM on Walker's computers (~300 MB left over).

TIMESVDPP_FAC_20_EPOCH_40_QRMSE_0.88668: See TIMESVDPP_QUAL_6.803 in
"good_predictions". This run did use userFacMatTime.

TIMESVDPP_NO_UFMT_FAC_200_EPOCH_40_QRMSE_0.8789: See TIMESVDPP_QUAL_7.620
in "good_predictions". This run did not use userFacMatTime.

TIMESVDPP_NO_UFMT_FAC_20_EPOCH_40_QRMSE_0.88863: See TIMESVDPP_QUAL_6.598
in "good_predictions". This run did not use userFacMatTime.

TIMESVDPP_NO_UFMT_FAC_500_EPOCH_40_QRMSE_0.87834: See TIMESVDPP_QUAL_7.679
in "good_predictions". This run did not use userFacMatTime.


SVD++ (overfit)
--------------------

SVDPP_FAC_2000_EPOCH_80_QRMSE_0.88415: See SVDPP_QUAL_7.069 in
"good_predictions" for more information.

SVDPP_FAC_1000_EPOCH_80_QRMSE_0.88479: See SVDPP_QUAL_7.001 in
"good_predictions". Hopefully there was some overfitting in this run.

SVDPP_FAC_100_EPOCH_80_QRMSE_0.88763: See SVDPP_QUAL_6.703 in
"good_predictions". The actual amount of overfitting in this run might not
have been too significant (unfortunately).


SVD++ (not overfit)
--------------------

SVDPP_FAC_750_EPOCH_25_QRMSE_0.89352: See SVDPP_QUAL_6.084 in
"good_predictions". Note that this predictor was **not** trained on probe.

SVDPP_FAC_200_EPOCH_25_QRMSE_0.89204: See SVDPP_QUAL_6.239 in
"good_predictions". Note that this predictor was **not** trained on probe.

SVDPP_FAC_500_EPOCH_40_QRMSE_0.88639: See SVDPP_QUAL_6.833 in
"good_predictions".


SVD (overfit)
--------------

SVD_FAC_2000_EPOCH_80_QRMSE_0.89078: See SVD_QUAL_6.372 in
"good_predictions".


SVD (not overfit)
------------------

SVD_FAC_1000_EPOCH_25_QRMSE_0.91179: See SVD_QUAL_4.163 in
"good_predictions".



Regular RBM (UToronto)
-----------------------

RBM_FAC_50_EPOCH_60_QRMSE_0.9184: See RBM_QUAL_3.469
in "good_predictions".

RBM_FAC_200_EPOCH_36_QRMSE_0.91109: This was an older prediction Sharon
e-mailed to me (Laksh), which has seven decimal places or so since it came
from an early run of RBM. I think this run was only used "base" as its
training set. The parameters were as follows:
    * rbm_alpha = 0.001
    * rbm_beta = 0.002
    * iter = 36, dec = 0.0001, factor = 200

RBM_FAC_30_EPOCH_120_QRMSE_0.91975: See RBM_QUAL_3.327
in "good_predictions".

RBM_FAC_30_EPOCH_120_QRMSE_QRMSE_0.91986: See RBM_QUAL_3.315
in "good_predictions".

RBM_FAC_50_EPOCH_120_QRMSE_0.91157: See RBM_QUAL_4.186 in
"good_predictions".

RBM_FAC_300_EPOCH_120_QRMSE_0.90897: See RBM_QUAL_4.597 in
"good_predictions".

RBM_FAC_400_EPOCH_60_QRMSE_0.90838: See RBM_QUAL_4.522 in
"good_predictions".

RBM_FAC_200_EPOCH_60_QRMSE_0.90429: See RBM_QUAL_4.952 in
"good_predictions".

RBM_FAC_200_EPOCH_57_QRMSE_0.91735: See RBM_QUAL_3.579 in
"good_predictions".

RBM_FAC_300_EPOCH_80_QRMSE_0.90637: See RBM_QUAL_4.710 in
"good_predictions".

RBM_FAC_150_EPOCH_120_QRMSE_0.90484: See RBM_QUAL_4.89 in
"good_predictions".

RBM_FAC_250_EPOCH_120_QRMSE_0.90725: See RBM_QUAL_4.64 in
"good_predictions".


SGD (GraphChi)
--------------

SGD_FAC_50_EPOCH_30_QRMSE_1.01966: See SGD_QUAL_-7.175 in
"good_predictions".

SGD_FAC_30_EPOCH_70_QRMSE_1.00172: See SGD_QUAL_-5.289 in
"good_predictions".

SGD_FAC_20_EPOCH_30_QRMSE_1.00199: See SGD_QUAL_-5.317 in
"good_predictions".

SGD_FAC_20_EPOCH_90_QRMSE_1.00147: See SGD_QUAL_-5.262 in
"good_predictions".

SGD_FAC_100_EPOCH_90_QRMSE_1.04922: See SGD_QUAL_-0.103 in
"good_predictions".


Global Effects
---------------

GLOBALS_GE_10_QRMSE_0.96283: See GLOBALS_QUAL_-1.201 in "good_predictions".


Residual kNN
-------------

GLOBALS_KNN_GE_10_MC_24_MW_30_QRMSE_0.94117: See
GLOBALS_KNN_COMBO_QUAL_1.075 in "good_predictions".

KNN_ON_TIMESVDPP_MC_30_MW_50_FAC_60_EPOCH_80_QRMSE_0.89256: For more
details, see KNN_ON_TIMESVDPP_QUAL_6.185 in "good_predictions".

KNN_ON_TIMESVDPP_MC_24_MW_400_FAC_60_EPOCH_40_QRMSE_0.8821: For more
details, see KNN_ON_TIMESVDPP_QUAL_7.284 in "good_predictions".

KNN_ON_RBM_FAC_50_EPOCH_60_MC_16_MW_400_QRMSE_0.91493: For more
details, see KNN_ON_RBM_QUAL_3.833 in "good_predictions".

KNN_ON_RBM_FAC_400_EPOCH_120_MC_16_MW_400_QRMSE_0.9132: For more
details, see KNN_ON_RBM_QUAL_4.015 in "good_predictions".

KNN_ON_RBM_FAC_100_EPOCH_38_MC_30_MW_50_QRMSE_0.91438: For more
details, see KNN_ON_RBM_QUAL_3.891 in "good_predictions".

KNN_ON_RBM_FACT_200_EPOCH_50_MC_30_MW_50_QRMSE_0.91562: For more
details, see KNN_ON_RBM_QUAL_3.760 in "good_predictions".

KNN_ON_RBM_FAC_200_EPOCH_50_MC_16_MW_400_QRMSE_0.94395: For more
details, see KNN_ON_RBM_QUAL_0.783 in "good_predictions".

KNN_ON_RBM_FAC_200_EPOCH_50_MC_30_MW_400_QRMSE_0.91818: For more
details, see KNN_ON_RBM_QUAL_3.492 in "good_predictions".

KNN_ON_SGD_FACT_20_EPOCH_90_MC_30_MW_50_QRMSE_0.956: For more
details, see KNN_ON_SGD_QUAL_-0.483 in "good_predictions".
